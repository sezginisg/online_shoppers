{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 5 Online Shoppers Intent Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "1. \n",
    "2.\n",
    "3.\n",
    "4.\n",
    "5.\n",
    "6.\n",
    "7.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Case: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from textwrap import wrap\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "              \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from IPython.display import Image  \n",
    "from pydotplus import graph_from_dot_data\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, precision_recall_curve\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('online_shoppers_intention.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Scrubbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative             0\n",
       "Administrative_Duration    0\n",
       "Informational              0\n",
       "Informational_Duration     0\n",
       "ProductRelated             0\n",
       "ProductRelated_Duration    0\n",
       "BounceRates                0\n",
       "ExitRates                  0\n",
       "PageValues                 0\n",
       "SpecialDay                 0\n",
       "Month                      0\n",
       "OperatingSystems           0\n",
       "Browser                    0\n",
       "Region                     0\n",
       "TrafficType                0\n",
       "VisitorType                0\n",
       "Weekend                    0\n",
       "Revenue                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Duplicated values\n",
    "df.duplicated().sum()\n",
    "# 125 values duplicated\n",
    "# Will leave them in as they could be duplicates by chance and \n",
    "# they are very small portion of our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Data Set Information:\n",
    "\n",
    "The dataset consists of feature vectors belonging to 12,330 sessions.\n",
    "The dataset was formed so that each session\n",
    "would belong to a different user in a 1-year period to avoid\n",
    "any tendency to a specific campaign, special day, user\n",
    "profile, or period.\n",
    "\n",
    "\n",
    "### 4.2 Attribute Information:\n",
    "\n",
    "The dataset consists of 10 numerical and 8 categorical attributes.\n",
    "The 'Revenue' attribute can be used as the class label.\n",
    "\n",
    "\"Administrative\", \"Administrative Duration\", \"Informational\", \"Informational Duration\", \"Product Related\" and \"Product Related Duration\" represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an action, e.g. moving from one page to another. The \"Bounce Rate\", \"Exit Rate\" and \"Page Value\" features represent the metrics measured by \"Google Analytics\" for each page in the e-commerce site. The value of \"Bounce Rate\" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (\"bounce\") without triggering any other requests to the analytics server during that session. The value of \"Exit Rate\" feature for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session. The \"Page Value\" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. The \"Special Day\" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. The dataset also includes operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 18 columns):\n",
      "Administrative             12330 non-null int64\n",
      "Administrative_Duration    12330 non-null float64\n",
      "Informational              12330 non-null int64\n",
      "Informational_Duration     12330 non-null float64\n",
      "ProductRelated             12330 non-null int64\n",
      "ProductRelated_Duration    12330 non-null float64\n",
      "BounceRates                12330 non-null float64\n",
      "ExitRates                  12330 non-null float64\n",
      "PageValues                 12330 non-null float64\n",
      "SpecialDay                 12330 non-null float64\n",
      "Month                      12330 non-null object\n",
      "OperatingSystems           12330 non-null int64\n",
      "Browser                    12330 non-null int64\n",
      "Region                     12330 non-null int64\n",
      "TrafficType                12330 non-null int64\n",
      "VisitorType                12330 non-null object\n",
      "Weekend                    12330 non-null bool\n",
      "Revenue                    12330 non-null bool\n",
      "dtypes: bool(2), float64(7), int64(7), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Screen for Categorical variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative             0.002190\n",
       "Administrative_Duration    0.270479\n",
       "Informational              0.001379\n",
       "Informational_Duration     0.102028\n",
       "ProductRelated             0.025223\n",
       "ProductRelated_Duration    0.774615\n",
       "BounceRates                0.151825\n",
       "ExitRates                  0.387429\n",
       "PageValues                 0.219303\n",
       "SpecialDay                 0.000487\n",
       "Month                      0.000811\n",
       "OperatingSystems           0.000649\n",
       "Browser                    0.001054\n",
       "Region                     0.000730\n",
       "TrafficType                0.001622\n",
       "VisitorType                0.000243\n",
       "Weekend                    0.000162\n",
       "Revenue                    0.000162\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are checking the ratio of unique values to the total number count for each column\n",
    "df.nunique()/df.count()\n",
    "# proportions of nuniques to total counts < 0.05 suggest categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop to visually inspect value counts for all variables\n",
    "# for col in df.columns:\n",
    "#     print(f'This is {col} value counts: \\n{df[col].value_counts()}.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset categorical and continuous features from dataframe for visualisations:\n",
    "df_cont = df[['Administrative_Duration', 'Informational_Duration', 'ProductRelated_Duration', 'ExitRates', 'PageValues', 'BounceRates']]\n",
    "df_cat = df.drop(df_cont.columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and Target subsetting:\n",
    "X = df.drop(columns=['Revenue'], axis =1)\n",
    "y = df['Revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 426)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the categorical variables in the training data and show the resulting DataFrame with proper column names\n",
    "ohe = OneHotEncoder()\n",
    "# subset continuous and categorical variables:\n",
    "X_cont = X[['Administrative_Duration', 'Informational_Duration', 'ProductRelated_Duration', 'ExitRates', 'PageValues', 'BounceRates']]\n",
    "X_cat = X.drop(df_cont.columns, axis=1)\n",
    "\n",
    "\n",
    "#Fit transform the variables and place them in a dataframe\n",
    "encoded_vars = ohe.fit_transform(X_cat).toarray()\n",
    "ohe_df = pd.DataFrame(encoded_vars, columns=ohe.get_feature_names(X_cat.columns))\n",
    "ohe_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 432)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset index and make a copy of continuous dataframe.\n",
    "X = X_cont.copy()\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concat into continuous and encoded categoricals into one training dataset:\n",
    "X = pd.concat([X_cont, ohe_df], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split and create a global seed\n",
    "seed=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split again to create train and validation \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Decision Tree fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5844, 0.8716, 0.7587)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree classifier fit \n",
    "clf = DecisionTreeClassifier(random_state = seed, criterion='entropy')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "#KFold cross validator instantiated:\n",
    "cv = KFold(n_splits=5, random_state=seed)\n",
    "\n",
    "# Use Crossvalidation to obtain Performance metrics: F1 Score and Accuracy\n",
    "F1_score = round(np.mean(cross_val_score(clf, X_train, y_train, cv=cv, scoring='f1')), 4)\n",
    "Acc_score = round(np.mean(cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')), 4)\n",
    "roc_AUC_score = round(np.mean(cross_val_score(clf, X_train, y_train, cv=cv, scoring='roc_auc')), 4)\n",
    "#Print F1 and Accuracy and ROC_AUC score for crossvalidation baseline decision tree\n",
    "F1_score, Acc_score, roc_AUC_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.4 Baseline Model - Plot the Decision Tree\n",
    "\n",
    "# Create DOT Data\n",
    "# dot_data = export_graphviz(clf, out_file=None,\n",
    "#                            feature_names=X_train.columns,\n",
    "#                            class_names=np.unique(y).astype('str'),\n",
    "#                            filled=True, rounded=True, special_characters=True)\n",
    "\n",
    "# Draw Graph \n",
    "# graph = graph_from_dot_data(dot_data) \n",
    "\n",
    "# Show graph\n",
    "# Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 Exploring Potential Improvements on Baseline Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Decision tree with Gini impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5641, 0.8686, 0.7429)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gini impurity Decision tree classifier fit \n",
    "clf1 = DecisionTreeClassifier(random_state = seed, criterion='gini')\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "# Use Crossvalidation to obtain Performance metrics: F1 Score and Accuracy\n",
    "F1_score = round(np.mean(cross_val_score(clf1, X_train, y_train, cv=cv, scoring='f1')), 4)\n",
    "Acc_score = round(np.mean(cross_val_score(clf1, X_train, y_train, cv=cv, scoring='accuracy')), 4)\n",
    "roc_AUC_score = round(np.mean(cross_val_score(clf1, X_train, y_train, cv=cv, scoring='roc_auc')), 4)\n",
    "\n",
    "#Print F1 and Accuracy and ROC_AUC score for crossvalidation baseline decision tree\n",
    "F1_score, Acc_score, roc_AUC_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Grid Search CV for Decision tree with Entropy impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='entropy',\n",
       "                                              max_depth=None, max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=42,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'criterion': ['entropy'],\n",
       "                         'max_depth': [None, 2, 3, 4, 5, 6],\n",
       "                         'min_samples_split': [10, 500, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entropy impurity performed better. Let's implement hyperparameter tuning with combinatoric grid searching.\n",
    "\n",
    "#initial Param grid:\n",
    "\n",
    "dt_param_grid = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [None, 2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [10, 500, 1000]\n",
    "}\n",
    "\n",
    "\n",
    "#insantiate the GridSearchCV\n",
    "dt_grid_search = GridSearchCV(clf, dt_param_grid, cv=3, return_train_score=True)\n",
    "\n",
    "# Fit to the data\n",
    "dt_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 90.65%\n",
      "Best Parameter Combination Found During Grid Search:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean training score\n",
    "dt_gs_training_score = np.mean(dt_grid_search.cv_results_['mean_train_score'])\n",
    "\n",
    "\n",
    "print(f\"Mean Training Score: {dt_gs_training_score :.2%}\")\n",
    "\n",
    "# Print best parameter combination found during grid search:\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "dt_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:0.6387259010896899, Precision Score:0.7003676470588235, Accuracy Score0.9040679254847295, F1 Score 0.6681280140289346\n"
     ]
    }
   ],
   "source": [
    "# Primary Param grid prediction scores: (Accuracy, Precision, Recall and F1)\n",
    "predictions = dt_grid_search.best_estimator_.predict(X_train)\n",
    "accuracy_score1 = accuracy_score(y_train, predictions)\n",
    "recall_score1 = recall_score(y_train, predictions)\n",
    "precision_score1 = precision_score(y_train, predictions)\n",
    "F1_score1 = f1_score(y_train, predictions)\n",
    "print(f'Recall Score:{recall_score1}, Precision Score:{precision_score1}, Accuracy Score{accuracy_score1}, F1 Score {F1_score1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='entropy',\n",
       "                                              max_depth=None, max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=42,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'criterion': ['entropy'], 'max_depth': [3],\n",
       "                         'min_samples_split': [2, 3, 5, 7, 9]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Secondary Param_Grid:\n",
    "\n",
    "dt_param_grid1 = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [3],\n",
    "    'min_samples_split': [2,3,5,7,9]\n",
    "}\n",
    "dt_grid_search1 = GridSearchCV(clf, dt_param_grid1, cv=3, return_train_score=True)\n",
    "\n",
    "# Fit to the data\n",
    "dt_grid_search1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 90.43%\n",
      "Best Parameter Combination Found During Grid Search:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Secondary Param Grid Mean train score \n",
    "dt_gs_training_score1 = np.mean(dt_grid_search1.cv_results_['mean_train_score'])\n",
    "\n",
    "print(f\"Mean Training Score: {dt_gs_training_score1 :.2%}\")\n",
    "\n",
    "# Secondary Param grid best combinations:\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "dt_grid_search1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:0.6387259010896899, Precision Score:0.7003676470588235, Accuracy Score0.9040679254847295, F1 Score 0.6681280140289346\n"
     ]
    }
   ],
   "source": [
    "#Predictions for secondary parameter grid and its related Recall, precision accuracy and F1 scores:\n",
    "predictions = dt_grid_search1.best_estimator_.predict(X_train)\n",
    "acc_score = accuracy_score(y_train, predictions)\n",
    "rec_score = recall_score(y_train, predictions)\n",
    "prec_score = precision_score(y_train, predictions)\n",
    "F1_score = f1_score(y_train, predictions)\n",
    "print(f'Recall Score:{rec_score}, Precision Score:{prec_score}, Accuracy Score{acc_score}, F1 Score {F1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Roc plot:\n",
    "# scores(model, X_train,y_train)\n",
    "# roc_plot(model,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 Ensemble Methods - Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score for Random Forest Classifier:  88.68%\n",
      "Recall Score:0.6387259010896899, Precision Score:0.7003676470588235, Accuracy Score0.9040679254847295, F1 Score 0.6681280140289346\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Random Forest and cross validate fit with the training data:\n",
    "rf_clf = RandomForestClassifier()\n",
    "mean_rf_cv_score = np.mean(cross_val_score(rf_clf, X_train, y_train, cv=3))\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "#print resulting mean score.\n",
    "print(f\"Mean Cross Validation Score for Random Forest Classifier: {mean_rf_cv_score : .2%}\")\n",
    "\n",
    "#Predictions and scores for out-of-box Random forest:\n",
    "predictions = dt_grid_search1.best_estimator_.predict(X_train)\n",
    "acc_score = accuracy_score(y_train, predictions)\n",
    "rec_score = recall_score(y_train, predictions)\n",
    "prec_score = precision_score(y_train, predictions)\n",
    "F1_score = f1_score(y_train, predictions)\n",
    "print(f'Recall Score:{rec_score}, Precision Score:{prec_score}, Accuracy Score{acc_score}, F1 Score {F1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Param Grid 1:\n",
    "\n",
    "# Create the Random_Grid\n",
    "random_grid = {'bootstrap': [True, False],\n",
    "             'max_depth': [10, 20, 30, 40, None],\n",
    "             'max_features': ['auto', 'sqrt'],\n",
    "             'min_samples_split': [2, 5, 10],\n",
    "             'n_estimators': [100, 200]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 900 is smaller than n_iter=1000. Running 900 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 27.2min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed: 72.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 114.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 207.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 815.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed: 827.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_sc...\n",
       "                                                    warm_start=False),\n",
       "                   iid='warn', n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# Will search across 1000 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf_clf, param_distributions = random_grid, n_iter = 1000, cv = 3, verbose=2, scoring='roc_auc', random_state=seed, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4612c248ba45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Predictions for secondary parameter grid and its related Recall, precision accuracy and F1 scores:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_ohe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0macc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrec_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprec_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_random' is not defined"
     ]
    }
   ],
   "source": [
    "#Predictions for secondary parameter grid and its related Recall, precision accuracy and F1 scores:\n",
    "predictions = rf_random.best_estimator_.predict(X_train)\n",
    "acc_score = accuracy_score(y_train, predictions)\n",
    "rec_score = recall_score(y_train, predictions)\n",
    "prec_score = precision_score(y_train, predictions)\n",
    "F1_score = f1_score(y_train, predictions)\n",
    "print(f'Recall Score:{rec_score}, Precision Score:{prec_score}, Accuracy Score{acc_score}, F1 Score {F1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 40,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV Param_grid Based on Random Search results:\n",
    "\n",
    "\n",
    "rf_param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [20, 30, 40, 50],\n",
    "    'max_features': [2, 3, 4],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'n_estimators': [200, 300, 400]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'max_depth': [20, 30, 40, 50],\n",
       "                         'max_features': [2, 3, 4],\n",
       "                         'min_samples_leaf': [3, 4, 5],\n",
       "                         'n_estimators': [200, 300, 400]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate and fit Grid Search 1\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=rf_param_grid, n_jobs= -1, scoring='roc_auc', verbose=2, cv=3)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 40,\n",
       " 'max_features': 4,\n",
       " 'min_samples_leaf': 3,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898364914363207"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary GridSearchCV:\n",
    "\n",
    "\n",
    "rf_param_grid = {\n",
    "    'criterion': ['entropy'],\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [40, 45, 50],\n",
    "    'max_features': [4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'n_estimators': [300, 350]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'criterion': ['entropy'],\n",
       "                         'max_depth': [40, 45, 50], 'max_features': [4, 5],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'n_estimators': [300, 350]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate and fit Grid Search 2\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=rf_param_grid, n_jobs= -1, scoring='roc_auc', verbose=2, cv=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 40,\n",
       " 'max_features': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 350}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9138123264576243"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tertiary GridSearchCV:\n",
    "\n",
    "\n",
    "rf_param_grid = {\n",
    "    'criterion': ['entropy'],\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [40],\n",
    "    'max_features': [5, 6, 7],\n",
    "    'min_samples_leaf': [1],\n",
    "    'n_estimators': [350, 400, 450]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'criterion': ['entropy'],\n",
       "                         'max_depth': [40], 'max_features': [5, 6, 7],\n",
       "                         'min_samples_leaf': [1],\n",
       "                         'n_estimators': [350, 400, 450]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate and fit Grid Search 3\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=rf_param_grid, n_jobs= -1, scoring='roc_auc', verbose=2, cv=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 40,\n",
       " 'max_features': 7,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 350}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9155076017937632"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'criterion': ['entropy'],\n",
       "                         'max_depth': [40], 'max_features': [7, 8, 9, 10, 11],\n",
       "                         'min_samples_leaf': [1], 'n_estimators': [350]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tertiary GridSearchCv\n",
    "rf_param_grid = {\n",
    "    'criterion': ['entropy'],\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [40],\n",
    "    'max_features': [7, 8, 9, 10, 11],\n",
    "    'min_samples_leaf': [1],\n",
    "    'n_estimators': [350]\n",
    "}\n",
    "#Instantiate and fit Grid Search 2\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=rf_param_grid, n_jobs= -1, scoring='roc_auc', verbose=2, cv=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 40,\n",
       " 'max_features': 11,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 350}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187968383282642"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'criterion': ['entropy'],\n",
       "                         'max_depth': [40], 'max_features': [10, 50, 200, 400],\n",
       "                         'min_samples_leaf': [1], 'n_estimators': [350]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quaternary GridSearchCv\n",
    "rf_param_grid = {\n",
    "    'criterion': ['entropy'],\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [40],\n",
    "    'max_features': [10, 50, 200, 400],\n",
    "    'min_samples_leaf': [1],\n",
    "    'n_estimators': [350]\n",
    "}\n",
    "#Instantiate and fit Grid Search 2\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=rf_param_grid, n_jobs= -1, scoring='roc_auc', verbose=2, cv=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 40,\n",
       " 'max_features': 50,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 350}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9271251957722065"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'criterion': ['entropy'],\n",
       "                         'max_depth': [40], 'max_features': [30, 50, 70, 90],\n",
       "                         'min_samples_leaf': [1], 'n_estimators': [350]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fifth GridSearchCv\n",
    "rf_param_grid = {\n",
    "    'criterion': ['entropy'],\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [40],\n",
    "    'max_features': [30, 50,70, 90],\n",
    "    'min_samples_leaf': [1],\n",
    "    'n_estimators': [350]\n",
    "}\n",
    "#Instantiate and fit Grid Search 2\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=rf_param_grid, n_jobs= -1, scoring='roc_auc', verbose=2, cv=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 40,\n",
       " 'max_features': 70,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 350}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279106797316398"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:  1.1min remaining:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=10, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'criterion': ['entropy'],\n",
       "                         'max_depth': [40], 'max_features': [65, 70, 75],\n",
       "                         'min_samples_leaf': [1], 'n_estimators': [350]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sixth GridSearchCv\n",
    "rf_param_grid = {\n",
    "    'criterion': ['entropy'],\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [40],\n",
    "    'max_features': [65, 70,75],\n",
    "    'min_samples_leaf': [1],\n",
    "    'n_estimators': [350]\n",
    "}\n",
    "#Instantiate and fit Grid Search 2\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=rf_param_grid, n_jobs= -1, scoring='roc_auc', verbose=2, cv=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 40,\n",
       " 'max_features': 65,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 350}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9274560834349468"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Threshold Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities from optimal model:\n",
    "\n",
    "optimal_model = grid_search.best_estimator_\n",
    "\n",
    "probas = optimal_model.predict_proba(X_train)\n",
    "\n",
    "y_train_rf_predict = cross_val_predict(optimal_model, X_train, y_train, cv=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign y_probability values as an ndarray\n",
    "y_prob = optimal_model.predict_proba(X_val)[:, 1]\n",
    "type(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain our False positive rate and True positive rate as wella s our Thresholds:\n",
    "fpr,tpr,threshold = roc_curve(y_val, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain confusion matrix values (TP, FP, TN, FN):\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_train_rf_predict).ravel()\n",
    "\n",
    "# Define Costs for Threshold Object Function and m values:\n",
    "\n",
    "cfp = 150\n",
    "ctn = 0\n",
    "cfn = 200\n",
    "ctp = -50\n",
    "\n",
    "# Define Prevalence (actual positives/all positives)\n",
    "prevalence = (tp + fn)/(tp+tn+fn+fp)\n",
    "\n",
    "#Metz's m:\n",
    "m = ((1 - prevalence)/prevalence)*((cfp - ctn)/(cfn - ctp))\n",
    "\n",
    "# Iterate through thresholds from roc_curve to calculate best objective funtion (fm)\n",
    "best_threshold = 0\n",
    "diff = 0\n",
    "for i in range(len(threshold)):\n",
    "    temp = tpr[i]-(m*fpr[i])\n",
    "    if temp>diff:\n",
    "        diff = temp\n",
    "        best_threshold = threshold[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11450793650793652"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print our Best Threshold:\n",
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
